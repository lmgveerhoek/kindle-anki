{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import sqlite3\n",
    "import argparse\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a connection to the database file, named vocab.db\n",
    "# We have retrieved this file from our kindle, and it contains the words we have looked up\n",
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to joint the two tables from LOOKUPS, BOOK_INFO and WORDS\n",
    "# We can do this by making use of the book_key from LOOKUPS and id from BOOK_INFO\n",
    "# To join the other tables we have to make use of the word_key from LOOKUPS and id from WORDS\n",
    "# The only columns we need are: word_key/id, word, title, usage\n",
    "def join_tables(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT word_key, word, title, usage FROM LOOKUPS JOIN WORDS ON LOOKUPS.word_key = WORDS.id JOIN BOOK_INFO ON LOOKUPS.book_key = BOOK_INFO.id\")\n",
    "    rows = cur.fetchall()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try our code\n",
    "def retrieve_rows(file):\n",
    "    conn = create_connection(file)\n",
    "    with conn:\n",
    "        rows = join_tables(conn)\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'vocab.db'\n",
    "rows = retrieve_rows(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to create a dataframe from the rows we have retrieved, so we can filter on a book title\n",
    "# Change the column names to something more readable: Word, Book, Context\n",
    "# We don't need the word_key, so we can drop this column\n",
    "def create_dataframe(rows):\n",
    "    df = pd.DataFrame(rows, columns=['Word_key', 'Word', 'Book', 'Context'])\n",
    "    df = df.drop(columns=['Word_key'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client to use the API\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in our joined tables, we want to determine the meaning of the word in the context of the usage. \n",
    "# We will use the OpenAI client to generate a response for each word\n",
    "def generate_definition(word, usage):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a language bot who EXCLUSIVELY returns the English definition of the word given the context, without explanation. The translation must at most be several words.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Define \\\"{word}\\\" in the context of \\\"{usage}\\\".\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the books from the dataframe\n",
    "def get_books(df):\n",
    "    return df['Book'].unique()\n",
    "\n",
    "# Print the books in the dataframe and index them\n",
    "def print_books(books):\n",
    "    for index, book in enumerate(books):\n",
    "        print(f\"{index}: {book}\")\n",
    "\n",
    "# Let a user choose a book from the list of books, by providing the index of the book\n",
    "# We will then filter the dataframe on the chosen book\n",
    "def choose_book(df):\n",
    "    books = get_books(df)\n",
    "    print_books(books)\n",
    "    book_index = int(input(\"Choose a book by providing the index: \"))\n",
    "    book = books[book_index]\n",
    "    return df[df['Book'] == book]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe on the chosen book\n",
    "filtered_words = choose_book(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 10 rows for testing\n",
    "filtered_words_ten = filtered_words.head(10)\n",
    "\n",
    "# For each row in the filtered words, we want to generate a definition and directly add this to the dataframe\n",
    "definitions = []\n",
    "results = []\n",
    "for index, row in filtered_words_ten.iterrows():\n",
    "    word = row[0]\n",
    "    usage = row[2]\n",
    "    definition = generate_definition(word, usage)\n",
    "    definitions.append(definition)\n",
    "    #a.append_row([row[1], response, row[3]])\n",
    "    results.append([row[0], definition, row[2], row[1]])\n",
    "df = pd.DataFrame(results, columns=['Word', 'Definition', 'Context', 'Book'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "df.to_csv('definitions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
